{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_Category.json.gz\n",
      "baselines.py\n",
      ".DS_Store\n",
      "train_Interactions.csv.gz\n",
      "predictions_Read.txt\n",
      "test_Category.json.gz\n",
      "pairs_Category.txt\n",
      ".ipynb_checkpoints\n",
      "pairs_Read.txt\n",
      "assignment1.ipynb\n",
      "pairs_Rating.txt\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir('assignment1'):\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)\n",
    "\n",
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        yield l.strip().split(',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num=190000\n",
    "df=pd.read_csv('assignment1/train_Interactions.csv.gz')\n",
    "\n",
    "userID_lst=df['userID'].get_values()[num:]\n",
    "rating_lst=len(userID_lst)*[-1]\n",
    "path='assignment1/train_Interactions.csv.gz'\n",
    "allBooks_train=[]\n",
    "userBooks_train=defaultdict(list)\n",
    "n=0\n",
    "usersPerBook_train=defaultdict(list)\n",
    "book_lst=[]\n",
    "for user, book, rating in readCSV(path):\n",
    "    if n<190000:\n",
    "        usersPerBook_train[book].append(user)\n",
    "        userBooks_train[user].append(book)\n",
    "        allBooks_train.append(book)\n",
    "        n+=1\n",
    "    else:\n",
    "        nonRead=np.setdiff1d(allBooks_train,userBooks_train[user])\n",
    "        random_book=random.choice(nonRead)\n",
    "        book_lst.append(random_book)\n",
    "        \n",
    "\n",
    "        \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_user=[*userID_lst,*userID_lst]\n",
    "valid_rating=[*df['rating'].get_values()[num:],*rating_lst]\n",
    "valid_book=[*df['bookID'].get_values()[num:],*book_lst]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookCount=defaultdict(int)\n",
    "totalRead=0\n",
    "n=0\n",
    "for uder, book,rating in readCSV(path):\n",
    "    if n<190000:\n",
    "        bookCount[book]+=1\n",
    "        totalRead+=1\n",
    "    else: continue\n",
    "mostPopular=[(bookCount[x], x) for x in bookCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostPopular=[(bookCount[x], x) for x in bookCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "return1=set()\n",
    "count=0\n",
    "for ic, i in mostPopular:\n",
    "    count+=ic\n",
    "    return1.add(i)\n",
    "    if count>totalRead/2: break\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=[]\n",
    "for i in range(20000):\n",
    "    if valid_book[i] in return1:\n",
    "        prediction.append(1)\n",
    "    else:\n",
    "        prediction.append(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_lst=[1 if x >=0 else 0 for x in valid_rating]\n",
    "accuracy=sum([prediction[i]==read_lst[i] for i in range(len(read_lst))])/len(read_lst)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6504"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "train_df=df.loc[:190000,:]\n",
    "train_df.shape\n",
    "train_df.head()\n",
    "\n",
    "train_user=train_df.userID.tolist()\n",
    "train_book=train_df.bookID.tolist()\n",
    "\n",
    "train_jsc=[]\n",
    "train_popularity=[]\n",
    "for i in range(len(train_book)):\n",
    "    train_jsc.append(mostSimilar(train_user[i], train_book[i]))\n",
    "    train_popularity.append(bookCount[train_book[i]])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>bookID</th>\n",
       "      <th>rating</th>\n",
       "      <th>jsc</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u79354815</td>\n",
       "      <td>b14275065</td>\n",
       "      <td>4</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u56917948</td>\n",
       "      <td>b82152306</td>\n",
       "      <td>5</td>\n",
       "      <td>0.017699</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u97915914</td>\n",
       "      <td>b44882292</td>\n",
       "      <td>5</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u49688858</td>\n",
       "      <td>b79927466</td>\n",
       "      <td>5</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u08384938</td>\n",
       "      <td>b05683889</td>\n",
       "      <td>2</td>\n",
       "      <td>0.021583</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      userID     bookID  rating       jsc  popularity\n",
       "0  u79354815  b14275065       4  0.016393         108\n",
       "1  u56917948  b82152306       5  0.017699         105\n",
       "2  u97915914  b44882292       5  0.058824          43\n",
       "3  u49688858  b79927466       5  0.035714          19\n",
       "4  u08384938  b05683889       2  0.021583         132"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['jsc']=train_jsc\n",
    "train_df['popularity']=train_popularity\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### accuracy=0.65105"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_popularity\n",
    "val_popularity=[]\n",
    "for i in valid_book:\n",
    "    val_popularity.append(bookCount[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5867\n",
      "0.6043\n",
      "0.6203\n",
      "0.6321\n",
      "0.63915\n",
      "0.6465\n",
      "0.65\n",
      "0.65355\n",
      "0.65475\n",
      "0.6548\n",
      "0.65515\n",
      "0.6551\n",
      "0.65465\n",
      "0.6544\n",
      "0.65425\n",
      "0.65315\n",
      "0.6519\n",
      "0.6504\n"
     ]
    }
   ],
   "source": [
    "for num in np.arange(1.1, 2, 0.05):\n",
    "    return1=set()\n",
    "    count=0\n",
    "    for ic, i in mostPopular:\n",
    "        count+=ic\n",
    "        return1.add(i)\n",
    "        if count>totalRead/num: break\n",
    "    prediction=[]\n",
    "    for i in range(20000):\n",
    "        if valid_book[i] in return1:\n",
    "            prediction.append(1)\n",
    "        else:\n",
    "            prediction.append(0)\n",
    "    read_lst=[1 if x >=0 else 0 for x in valid_rating]\n",
    "    accuracy=sum([prediction[i]==read_lst[i] for i in range(len(read_lst))])/len(read_lst)\n",
    "    print(accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### as listed above, the best accuracy is 0.65715 with totalRead/1.5, whihc is approximately about 67th percentile of popularity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training dataset\n",
    "#userBooks_train\n",
    "#allBooks_train\n",
    "#validation dataset\n",
    "#valid_user\n",
    "#valid_book\n",
    "#valid_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(s1, s2):\n",
    "    numer=len(set(s1).intersection(set(s2)))\n",
    "    denom=len(set(s1).union(set(s2)))\n",
    "    return numer/denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_book=defaultdict(set)\n",
    "for i in range(len(valid_user)):\n",
    "    user_book[valid_user[i]]=valid_book[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "userBooks=userBooks_train\n",
    "usersPerBook=usersPerBook_train       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(s1, s2):\n",
    "    numer=len(set(s1).intersection(set(s2)))\n",
    "    denom=len(set(s1).union(set(s2)))\n",
    "    return numer/denom\n",
    "def mostSimilar(user,book):\n",
    "    similarities=[]\n",
    "    users=usersPerBook[book]\n",
    "    books=userBooks[user]\n",
    "    for b in books:\n",
    "        if b==book: continue\n",
    "        s1=users\n",
    "        s2=usersPerBook[b]\n",
    "        sim=jaccard(s1,s2)\n",
    "        similarities.append(sim)\n",
    "    similarities.sort(reverse=True)\n",
    "    if len(similarities)==0:\n",
    "        return 0\n",
    "    return similarities[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=[]\n",
    "for i in range(len(valid_user)):\n",
    "    result.append(mostSimilar(valid_user[i], valid_book[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-f0cc9ab65494>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_read\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrating\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mval_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'val_df' is not defined"
     ]
    }
   ],
   "source": [
    "len(result)\n",
    "train_df.head()\n",
    "train_read=[1 if x>=0 else 0 for x in train_df.rating.tolist()]\n",
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-3a5a574f4861>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'jsc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'popularity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_read\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: fit() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "#val_jsc: result\n",
    "#val_popularity:  val_popularity\n",
    "from sklearn import linear_model\n",
    "model=linear_model.LogisticRegression\n",
    "model.fit(X=, y=train_read)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01919008666274347\n",
      "0.013504327576459594\n"
     ]
    }
   ],
   "source": [
    "upper=np.mean(result[:10000])\n",
    "lower=np.mean(result[10000:])\n",
    "print(upper)\n",
    "print(lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.5915\n",
      "0.5915\n",
      "0.59215\n",
      "0.5955\n",
      "0.59845\n",
      "0.6056\n",
      "0.6113\n",
      "0.61755\n",
      "0.6205\n",
      "0.62095\n",
      "0.62245\n",
      "0.6218\n",
      "0.6193\n",
      "0.61585\n",
      "0.6097\n",
      "0.6045\n",
      "0.59815\n",
      "0.5903\n",
      "0.58385\n",
      "0.5772\n",
      "0.5689\n",
      "0.5621\n",
      "0.557\n",
      "0.5503\n",
      "0.54515\n",
      "0.5396\n",
      "0.5366\n",
      "0.5324\n",
      "0.5289\n"
     ]
    }
   ],
   "source": [
    "for threshold in np.arange(0.0,0.030, 0.001):\n",
    "    prediction=[1 if x >= threshold else 0 for x in result]\n",
    "    accuracy=sum([prediction[i]==read_lst[i] for i in range(len(read_lst))])/len(read_lst)\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### as listed above, the best accuracy is 0.62635, with the threshold of 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostSimilar(user,book):\n",
    "    \n",
    "    similarities=[]\n",
    "    users=usersPerBook[book]\n",
    "    books=userBooks[user]\n",
    "    for b in books:\n",
    "        if b==book: continue\n",
    "        s1=users\n",
    "        s2=usersPerBook[b]\n",
    "        sim=jaccard(s1,s2)\n",
    "        similarities.append(sim)\n",
    "    similarities.sort(reverse=True)\n",
    "    \n",
    "    return similarities[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "return1_ls=set()\n",
    "count=0\n",
    "num=1.5\n",
    "for ic, i in mostPopular:\n",
    "    count+=ic\n",
    "    return1_ls.add(i)\n",
    "    if count>totalRead/num: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity=[]\n",
    "for i in range(len(valid_user)):\n",
    "    similarity.append(mostSimilar(valid_user[i], valid_book[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=[]\n",
    "\n",
    "for i in range(len(valid_user)):\n",
    "    if similarity[i]>=0.01 and (valid_book[i] in return1_ls)==True:\n",
    "        prediction.append(1)\n",
    "    else:\n",
    "        prediction.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8507"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.66105\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accuracy=sum([prediction[i]==read_lst[i] for i in range(len(read_lst))])/len(read_lst)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The accuracy of this predictor is 0.66595, which is higher than baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Read.txt\", 'w')\n",
    "for l in open(\"assignment1/pairs_Read.txt\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "    #header\n",
    "        predictions.write(\"userID-bookID,prediction\\n\")\n",
    "        continue\n",
    "    user,book = l.strip().split('-')\n",
    "    similarities=[]\n",
    "    users=usersPerBook[book]\n",
    "    books=userBooks[user]\n",
    "    for b in books:\n",
    "        if b==book: continue\n",
    "        s1=users\n",
    "        s2=usersPerBook[b]\n",
    "        sim=jaccard(s1,s2)\n",
    "        similarities.append(sim)\n",
    "    similarities.sort(reverse=True)\n",
    "    sim=similarities[0]\n",
    "    if sim>0.01 and (book in return1_ls)==True:\n",
    "        predictions.write(user+'-'+book+',1\\n')\n",
    "    else:\n",
    "        predictions.write(user+'-'+book+',0\\n')\n",
    "predictions.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath=\"assignment1/train_Category.json.gz\"\n",
    "reviews=[]\n",
    "for l in readGz(filePath):\n",
    "    reviews.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "num=190000\n",
    "train=reviews[:num]\n",
    "valid=reviews[num:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCount=defaultdict(int)\n",
    "punctuation=set(string.punctuation)\n",
    "for i in train:\n",
    "    r=''.join([c for c in i['review_text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        wordCount[w]+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=[(wordCount[w], w) for w in wordCount]\n",
    "count.sort(reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[c[1] for c in count[:1000]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### words represents the 1000 most common words across the reviews in training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1421430, 'the'),\n",
       " (858918, 'and'),\n",
       " (754129, 'a'),\n",
       " (716863, 'to'),\n",
       " (699878, 'i'),\n",
       " (622766, 'of'),\n",
       " (420605, 'is'),\n",
       " (408519, 'in'),\n",
       " (392647, 'it'),\n",
       " (370479, 'this')]"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These are the 10 most common words along with thier frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordId=dict(zip(words, range(len(words))))\n",
    "wordSet=set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum):\n",
    "    feat=[0]*len(words)\n",
    "    t=''.join([c for c in datum['review_text'].lower() if c not in punctuation])\n",
    "    for w in r.split():\n",
    "        if w in words:\n",
    "            feat[wordId[w]]+=1\n",
    "    feat.append(1)#offset\n",
    "    return feat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5       , 0.66666667])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.array([1,2])\n",
    "b=np.array([2,3])\n",
    "a/b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "for i in train:\n",
    "    feat=feature(i)\n",
    "    X.append(feat)\n",
    "Y=[d['genreID'] for d in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_v=[]\n",
    "for i in valid:\n",
    "    feat=feature(i)\n",
    "    X_v.append(feat)\n",
    "Y_v=[d['genreID'] for d in valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=LogisticRegression()\n",
    "model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict(X_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3603\n"
     ]
    }
   ],
   "source": [
    "accuracy=sum([pred[i]==Y_v[i] for i in range(len(pred))])/len(pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### accuracy on validation set is 0.3603"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3603\n"
     ]
    }
   ],
   "source": [
    "num=2000\n",
    "words=[c[1] for c in count[:num]]\n",
    "wordId=dict(zip(words, range(len(words))))\n",
    "wordSet=set(words)\n",
    "X=[]\n",
    "for i in train:\n",
    "    feat=feature(i)\n",
    "    X.append(feat)\n",
    "Y=[d['genreID'] for d in train]\n",
    "X_v=[]\n",
    "for i in valid:\n",
    "    feat=feature(i)\n",
    "    X_v.append(feat)\n",
    "Y_v=[d['genreID'] for d in valid]\n",
    "model=LogisticRegression()\n",
    "model.fit(X,Y)\n",
    "pred=model.predict(X_v)\n",
    "accuracy=sum([pred[i]==Y_v[i] for i in range(len(pred))])/len(pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2001"
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model=LogisticRegression(C=0.1)\n",
    "model.fit(X,Y)\n",
    "pred=model.predict(X_v)\n",
    "accuracy=sum([pred[i]==Y_v[i] for i in range(len(pred))])/len(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3603\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16995\n",
      "13904\n",
      "68989\n",
      "51735\n"
     ]
    }
   ],
   "source": [
    "max(Y)\n",
    "for i in range(4):\n",
    "    print(Y.count(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
